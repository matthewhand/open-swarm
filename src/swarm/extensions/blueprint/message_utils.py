"""
Utilities for repairing message payloads specific to blueprint extensions.
Includes truncation logic tailored for preserving assistant/tool message pairs.
"""

import json
import logging
from typing import List, Dict, Any

# Import core utilities if possible, with fallback
try:
    from swarm.utils.message_utils import filter_duplicate_system_messages
except ImportError:
    logger = logging.getLogger(__name__) # Ensure logger is defined for fallback
    logger.warning("Could not import filter_duplicate_system_messages from core utils.")
    def filter_duplicate_system_messages(messages):
        # Basic fallback implementation
        filtered = []
        system_found = False
        for msg in messages:
             if isinstance(msg, dict) and msg.get("role") == "system":
                 if not system_found:
                     filtered.append(msg)
                     system_found = True
             else:
                 filtered.append(msg)
        return filtered

# Import get_token_count from the correct centralized location
try:
    # Assume get_token_count exists in context_utils as used elsewhere
    from swarm.utils.context_utils import get_token_count
except ImportError:
     logger = logging.getLogger(__name__) # Ensure logger is defined for fallback
     logger.error("CRITICAL: Cannot import get_token_count from swarm.utils.context_utils. Token counting will fail.")
     # Define a dummy fallback to prevent NameError, but log error
     def get_token_count(text: Any, model: str) -> int:
         # The mock in tests uses content length, let's somewhat mimic that
         try:
             if isinstance(text, str) and text.strip().startswith('{'):
                 msg_dict = json.loads(text)
                 return len(msg_dict.get("content", "") or "")
             elif isinstance(text, dict):
                 return len(text.get("content", "") or "")
         except Exception:
             pass
         return len(str(text).split()) # Very rough fallback

logger = logging.getLogger(__name__)

def repair_message_payload(messages: List[Dict[str, Any]], debug: bool = False) -> List[Dict[str, Any]]:
    """
    Repair the message sequence by ensuring tool messages follow their corresponding assistant calls.
    Handles potentially orphaned tool messages by inserting a dummy assistant call if necessary.
    """
    if not isinstance(messages, list):
        logger.error(f"Invalid messages type for repair: {type(messages)}. Returning empty list.")
        return []

    if debug: logger.debug(f"Starting payload repair. Initial messages: {len(messages)}")
    # Step 1: Filter duplicate system messages (usually keep only the first)
    messages = filter_duplicate_system_messages(messages)
    if debug: logger.debug(f"After filter_duplicate_system: {len(messages)} messages")

    # Step 2: Create set of valid tool_call_ids generated by assistant messages
    valid_tool_call_ids = set()
    for msg in messages:
        if isinstance(msg, dict) and msg.get("role") == "assistant" and isinstance(msg.get("tool_calls"), list):
            for tc in msg.get("tool_calls", []):
                if isinstance(tc, dict) and "id" in tc:
                    valid_tool_call_ids.add(tc["id"])
    if debug: logger.debug(f"Valid tool_call_ids from assistant messages: {valid_tool_call_ids}")

    # Step 3: Filter out tool messages with invalid/missing tool_call_ids
    filtered_messages = []
    for msg in messages:
         if isinstance(msg, dict):
             if msg.get("role") == "tool":
                  tool_call_id = msg.get("tool_call_id")
                  if tool_call_id in valid_tool_call_ids:
                       filtered_messages.append(msg)
                  else:
                       logger.warning(f"Filtering out tool message with invalid/unknown tool_call_id: {tool_call_id}. Message: {msg}")
             else:
                  filtered_messages.append(msg)
         else:
              logger.warning(f"Skipping non-dictionary item during filtering: {type(msg)}")
    if debug: logger.debug(f"After filtering invalid tool messages: {len(filtered_messages)} messages")


    # Step 4: Reorder and potentially insert dummy assistant calls for orphaned tools
    final_sequence = []
    i = 0
    while i < len(filtered_messages):
        msg = filtered_messages[i]
        current_role = msg.get("role")

        if current_role == "assistant" and msg.get("tool_calls"):
            assistant_msg = msg
            final_sequence.append(assistant_msg)
            expected_tool_ids = {tc.get("id") for tc in assistant_msg.get("tool_calls", []) if isinstance(tc, dict)}
            found_tool_ids = set()
            j = i + 1
            while j < len(filtered_messages):
                next_msg = filtered_messages[j]
                if next_msg.get("role") == "tool" and next_msg.get("tool_call_id") in expected_tool_ids:
                     final_sequence.append(next_msg)
                     found_tool_ids.add(next_msg["tool_call_id"])
                     j += 1
                     if found_tool_ids == expected_tool_ids: break
                elif next_msg.get("role") != "tool" or next_msg.get("tool_call_id") not in expected_tool_ids:
                    break
                else: j += 1

            missing_ids = expected_tool_ids - found_tool_ids
            if missing_ids:
                 logger.warning(f"Assistant requested tool calls ({missing_ids}) but corresponding tool messages were not found or filtered out.")

            i = j

        elif current_role == "tool":
            tool_call_id = msg.get("tool_call_id")
            tool_name = msg.get("name", msg.get("tool_name", "unknown_tool"))
            logger.warning(f"Found potentially orphaned tool message (ID: {tool_call_id}, Name: {tool_name}). Inserting preceding dummy assistant call.")
            dummy_assistant_call = {
                "role": "assistant", "content": None,
                "tool_calls": [{"id": tool_call_id, "type": "function", "function": {"name": tool_name, "arguments": "{}"}}]
            }
            final_sequence.append(dummy_assistant_call)
            final_sequence.append(msg)
            i += 1

        else:
            final_sequence.append(msg)
            i += 1

    if debug:
        final_roles = [m.get('role') for m in final_sequence if isinstance(m, dict)]
        logger.debug(f"Payload repair finished. Final messages: {len(final_sequence)}. Roles: {final_roles}")
    return final_sequence


def validate_message_sequence(messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Ensures basic structural validity of messages, primarily that 'tool' role messages
    have a corresponding 'assistant' message with matching 'tool_call_id' earlier in the sequence.
    """
    if not isinstance(messages, list):
        logger.error(f"Invalid messages type for validation: {type(messages)}. Returning empty list.")
        return []

    logger.debug(f"Validating message sequence integrity ({len(messages)} messages).")
    valid_messages = []
    valid_tool_call_ids_encountered = set()

    for msg in messages:
        if not isinstance(msg, dict):
             logger.warning(f"Skipping non-dictionary item during sequence validation: {type(msg)}")
             continue

        role = msg.get("role")

        if role == "assistant":
            valid_messages.append(msg)
            if isinstance(msg.get("tool_calls"), list):
                 for tc in msg.get("tool_calls", []):
                     if isinstance(tc, dict) and "id" in tc:
                         valid_tool_call_ids_encountered.add(tc["id"])
        elif role == "tool":
            tool_call_id = msg.get("tool_call_id")
            if tool_call_id in valid_tool_call_ids_encountered:
                 valid_messages.append(msg)
            else:
                 logger.warning(f"Filtering out 'tool' message with ID '{tool_call_id}' because no corresponding 'assistant' tool_call was found earlier in the sequence.")
        else:
            valid_messages.append(msg)

    if len(valid_messages) != len(messages):
         logger.debug(f"Validation removed {len(messages) - len(valid_messages)} messages.")
    else:
         logger.debug("Message sequence validation passed.")
    return valid_messages


# --- Truncation Functions ---

def truncate_preserve_pairs(messages: List[Dict[str, Any]], model: str, max_tokens: int, max_messages: int) -> List[Dict[str, Any]]:
    """Truncate preserving assistant/tool pairs, system message, within token/message limits."""
    system_msgs = []
    non_system_msgs = []
    system_found = False
    for msg in messages:
         if isinstance(msg, dict):
              if msg.get("role") == "system" and not system_found:
                   system_msgs.append(msg)
                   system_found = True
              elif msg.get("role") != "system":
                   non_system_msgs.append(msg)

    system_tokens = sum(get_token_count(json.dumps(msg), model) for msg in system_msgs)
    target_non_system_msg_count = max(0, max_messages - len(system_msgs))
    target_non_system_token_count = max(0, max_tokens - system_tokens)

    try:
         msg_tokens = [(msg, get_token_count(json.dumps(msg), model)) for msg in non_system_msgs]
    except Exception as e:
         logger.error(f"Error calculating initial tokens for truncation: {e}. Using approximate counts.")
         msg_tokens = [(msg, get_token_count(str(msg.get("content", "")), model) + 10) for msg in non_system_msgs]

    current_total_tokens = sum(t for _, t in msg_tokens)
    if len(non_system_msgs) <= target_non_system_msg_count and current_total_tokens <= target_non_system_token_count:
        logger.debug(f"History within limits ({len(non_system_msgs)} non-system msgs, {current_total_tokens} tokens). No truncation needed.")
        return system_msgs + non_system_msgs

    logger.debug(f"Truncation needed. Current: {len(non_system_msgs)} msgs, {current_total_tokens} tokens. Target: {target_non_system_msg_count} msgs, {target_non_system_token_count} tokens.")

    truncated = []
    total_tokens = 0
    kept_indices = set()
    i = len(msg_tokens) - 1
    while i >= 0 and len(truncated) < target_non_system_msg_count:
        if i in kept_indices:
             i -= 1
             continue

        msg, tokens = msg_tokens[i]
        current_role = msg.get("role")

        if current_role == "tool" and "tool_call_id" in msg:
            tool_call_id = msg["tool_call_id"]
            assistant_idx = i - 1
            pair_found_and_added = False
            while assistant_idx >= 0:
                 if assistant_idx in kept_indices:
                      assistant_idx -= 1
                      continue

                 prev_msg, prev_tokens = msg_tokens[assistant_idx]
                 if prev_msg.get("role") == "assistant" and prev_msg.get("tool_calls"):
                     if any(tc.get("id") == tool_call_id for tc in prev_msg.get("tool_calls", []) if isinstance(tc, dict)):
                          if total_tokens + tokens + prev_tokens <= target_non_system_token_count and len(truncated) + 2 <= target_non_system_msg_count:
                               truncated.insert(0, prev_msg)
                               truncated.insert(1, msg)
                               total_tokens += tokens + prev_tokens
                               kept_indices.add(i)
                               kept_indices.add(assistant_idx)
                               pair_found_and_added = True
                               i = assistant_idx - 1
                               break
                          else:
                               logger.debug(f"Pair for tool {tool_call_id} found but doesn't fit limits. Skipping pair.")
                               break
                 if i - assistant_idx > 10 or prev_msg.get("role") == "user": break
                 assistant_idx -= 1

            if not pair_found_and_added:
                 logger.debug(f"Skipping lone tool message {tool_call_id}.")
                 i -= 1

        elif current_role == "assistant" and isinstance(msg.get("tool_calls"), list):
             assistant_msg = msg
             assistant_tokens = tokens
             expected_tool_ids = {tc.get("id") for tc in assistant_msg.get("tool_calls", []) if isinstance(tc, dict)}
             found_tools_data = []
             indices_of_found_tools = []
             temp_tool_tokens = 0
             j = i + 1
             while j < len(msg_tokens):
                  tool_msg, tool_tokens = msg_tokens[j]
                  tool_msg_call_id = tool_msg.get("tool_call_id")
                  if tool_msg.get("role") == "tool" and tool_msg_call_id in expected_tool_ids:
                      if j not in kept_indices:
                           found_tools_data.append((tool_msg, tool_tokens))
                           indices_of_found_tools.append(j)
                           temp_tool_tokens += tool_tokens
                  elif tool_msg.get("role") != "tool": break
                  j += 1

             pair_tokens = assistant_tokens + temp_tool_tokens
             pair_len = 1 + len(found_tools_data)
             if total_tokens + pair_tokens <= target_non_system_token_count and len(truncated) + pair_len <= target_non_system_msg_count:
                  truncated.insert(0, assistant_msg)
                  kept_indices.add(i)
                  tool_insert_index = 1
                  for tool_idx, (tool_d_msg, _) in zip(indices_of_found_tools, found_tools_data):
                       truncated.insert(tool_insert_index, tool_d_msg)
                       kept_indices.add(tool_idx)
                       tool_insert_index += 1
                  total_tokens += pair_tokens
                  i -= 1
             else:
                  logger.debug(f"Skipping assistant message (idx {i}) and its tools as the pair exceeds limits.")
                  i -= 1

        else:
             if total_tokens + tokens <= target_non_system_token_count and len(truncated) < target_non_system_msg_count:
                  truncated.insert(0, msg)
                  total_tokens += tokens
                  kept_indices.add(i)
                  i -= 1
             else:
                  logger.debug(f"Stopping truncation: Message {i} ({current_role}) doesn't fit limits (Tokens: {total_tokens+tokens}/{target_non_system_token_count}, Msgs: {len(truncated)+1}/{target_non_system_msg_count}).")
                  break

    final_messages = system_msgs + truncated
    final_token_check = sum(get_token_count(json.dumps(m), model) for m in final_messages)
    logger.debug(f"Truncated to {len(final_messages)} messages ({len(system_msgs)} sys, {len(truncated)} non-sys), {final_token_check} tokens (preserve_pairs).")
    return final_messages

def truncate_strict_token(messages: List[Dict[str, Any]], model: str, max_tokens: int, max_messages: int) -> List[Dict[str, Any]]:
    # Currently aliased to preserve_pairs as the logic is similar
    logger.debug("Using 'truncate_preserve_pairs' logic for 'strict_token' mode.")
    return truncate_preserve_pairs(messages, model, max_tokens, max_messages)

def truncate_recent_only(messages: List[Dict[str, Any]], model: str, max_context_messages: int) -> List[Dict[str, Any]]:
    """Keep most recent N messages, ignoring token limits but respecting max_context_messages."""
    system_msgs = []
    non_system_msgs = []
    system_found = False
    for msg in messages:
         if isinstance(msg, dict):
              if msg.get("role") == "system" and not system_found:
                   system_msgs.append(msg)
                   system_found = True
              elif msg.get("role") != "system":
                   non_system_msgs.append(msg)

    target_non_system_count = max(0, max_context_messages - len(system_msgs))

    # Corrected slicing logic for target_non_system_count=0
    if target_non_system_count > 0:
        truncated_non_system = non_system_msgs[-target_non_system_count:]
    else:
        truncated_non_system = [] # Explicitly take empty list if count is 0

    final_messages = system_msgs + truncated_non_system
    final_tokens = sum(get_token_count(json.dumps(msg), model) for msg in final_messages) # Calculate tokens for info
    logger.debug(f"Truncated to {len(final_messages)} messages ({len(system_msgs)} sys, {len(truncated_non_system)} non-sys), {final_tokens} tokens (recent_only).")
    return final_messages

