# Zeus Blueprint - merged from DivineOpsBlueprint
# (autogenerated by Cascade)

import asyncio
import logging
import os
import sys
from typing import Any, ClassVar

from swarm.core.output_utils import get_spinner_state, print_operation_box

# Ensure src is in path for BlueprintBase import
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
src_path = os.path.join(project_root, 'src')
if src_path not in sys.path: sys.path.insert(0, src_path)

try:
    from openai import AsyncOpenAI

    from agents import Agent, Runner, Tool, function_tool
    from agents.mcp import MCPServer
    from agents.models.interface import Model
    from agents.models.openai_chatcompletions import OpenAIChatCompletionsModel
    from swarm.core.blueprint_base import BlueprintBase
    from swarm.core.blueprint_ux import BlueprintUX
except ImportError as e:
    print(f"ERROR: Import failed in ZeusBlueprint: {e}. Check 'openai-agents' install and project structure.")
    print(f"sys.path: {sys.path}")
    sys.exit(1)

logger = logging.getLogger(__name__)

# --- Agent Instructions ---
# (copy all *_instructions from DivineOpsBlueprint)

zeus_instructions = """
You are Zeus, Product Owner and Coordinator of the Divine Ops team.
Your goal is to manage the software development lifecycle based on user requests.
1. Understand the user's request (e.g., "design a user login system", "deploy the latest changes", "fix bug X").
2. Delegate tasks to the appropriate specialist agent using their respective Agent Tool:
    - Odin: For high-level architecture, design, research.
    - Hermes: For breaking down features into technical tasks, system checks.
    - Hephaestus: For primary coding and implementation.
    - Hecate: For specific coding assistance requested by Hephaestus (via you).
    - Thoth: For database schema/data changes, code updates related to DB.
    - Mnemosyne: For DevOps, deployment, infrastructure tasks.
    - Chronos: For writing documentation.
3. Provide clear context and requirements when delegating.
4. Synthesize the results and progress reports from your team.
5. Provide the final update or result to the user.
Available Agent Tools: Odin, Hermes, Hephaestus, Hecate, Thoth, Mnemosyne, Chronos.
"""

odin_instructions = """
You are Odin, the architect and research specialist of the Divine Ops team.
Handle high-level architecture, design, and research tasks delegated by Zeus.
Collaborate with other agents as needed, and provide clear, actionable architectural plans and research findings.
"""

hermes_instructions = """
You are Hermes, the technical task breakdown and system check specialist.
Your job is to decompose features into technical tasks and perform system checks as needed.
"""

hephaestus_instructions = """
You are Hephaestus, the primary coder and implementer.
Write, refactor, and optimize code as delegated by Zeus or other agents.
"""

hecate_instructions = """
You are Hecate, a specialist for specific coding assistance.
Assist Hephaestus or others with challenging code problems or reviews.
"""

thoth_instructions = """
You are Thoth, responsible for database schema and data changes.
Handle all DB-related code updates and migrations as delegated.
"""

mnemosyne_instructions = """
You are Mnemosyne, the DevOps and deployment specialist.
Manage infrastructure, CI/CD, and deployment tasks for the Divine Ops team.
"""

chronos_instructions = """
You are Chronos, the documentation specialist.
Write and maintain technical documentation for all projects and deliverables.
"""

# ... (all other *_instructions copied here)

# --- FileOps Tool Logic Definitions ---
class PatchedFunctionTool:
    def __init__(self, func, name):
        self.func = func
        self.name = name

def read_file(path: str) -> str:
    try:
        with open(path) as f:
            return f.read()
    except Exception as e:
        return f"ERROR: {e}"

def write_file(path: str, content: str) -> str:
    try:
        with open(path, 'w') as f:
            f.write(content)
        return "OK: file written"
    except Exception as e:
        return f"ERROR: {e}"

def list_files(directory: str = '.') -> str:
    try:
        return '\n'.join(os.listdir(directory))
    except Exception as e:
        return f"ERROR: {e}"

def execute_shell_command(command: str) -> str:
    import subprocess
    try:
        result = subprocess.run(command, shell=True, capture_output=True, text=True)
        return result.stdout + result.stderr
    except Exception as e:
        return f"ERROR: {e}"

read_file_tool = PatchedFunctionTool(read_file, 'read_file')
write_file_tool = PatchedFunctionTool(write_file, 'write_file')
list_files_tool = PatchedFunctionTool(list_files, 'list_files')
execute_shell_command_tool = PatchedFunctionTool(execute_shell_command, 'execute_shell_command')

# --- ZeusBlueprint (was DivineOpsBlueprint) ---
class ZeusBlueprint(BlueprintBase):
    """
    Zeus Blueprint: Merged from DivineOpsBlueprint
    """
    # --- DivineOpsBlueprint metadata, caches, and methods ---
    metadata: ClassVar[dict[str, Any]] = {
        "name": "ZeusBlueprint",
        "title": "Divine Ops: Streamlined Software Dev & Sysadmin Team",
        "description": "Zeus leads a pantheon for software dev & sysadmin tasks, coordinating via agent-as-tool delegation.",
        "version": "1.1.0", # Refactored version
        "author": "Open Swarm Team (Refactored)",
        "tags": ["software development", "sysadmin", "devops", "multi-agent", "collaboration", "delegation"],
        "required_mcp_servers": [
            "memory",
            "filesystem",
            "mcp-shell",
            "sqlite",
            "sequential-thinking",
            "brave-search",
        ],
        "env_vars": [
            "ALLOWED_PATH",
            "SQLITE_DB_PATH",
            "BRAVE_API_KEY"
        ]
    }

    _openai_client_cache: dict[str, AsyncOpenAI] = {}
    _model_instance_cache: dict[str, Model] = {}

    def _get_model_instance(self, profile_name: str) -> Model:
        if profile_name in self._model_instance_cache:
            logger.debug(f"Using cached Model instance for profile '{profile_name}'.")
            return self._model_instance_cache[profile_name]
        logger.debug(f"Creating new Model instance for profile '{profile_name}'.")
        profile_data = self.get_llm_profile(profile_name)
        if not profile_data:
            logger.critical(f"LLM profile '{profile_name}' (or 'default') not found.")
            raise ValueError(f"Missing LLM profile configuration for '{profile_name}' or 'default'.")
        provider = profile_data.get("provider", "openai").lower()
        model_name = profile_data.get("model")
        if not model_name:
            logger.critical(f"LLM profile '{profile_name}' missing 'model' key.")
            raise ValueError(f"Missing 'model' key in LLM profile '{profile_name}'.")
        if provider != "openai":
            logger.error(f"Unsupported LLM provider '{provider}'.")
            raise ValueError(f"Unsupported LLM provider: {provider}")
        client_cache_key = f"{provider}_{profile_data.get('base_url')}"
        if client_cache_key not in self._openai_client_cache:
            client_kwargs = { "api_key": profile_data.get("api_key"), "base_url": profile_data.get("base_url") }
            filtered_kwargs = {k: v for k, v in client_kwargs.items() if v is not None}
            log_kwargs = {k:v for k,v in filtered_kwargs.items() if k != 'api_key'}
            logger.debug(f"Creating new AsyncOpenAI client for '{profile_name}': {log_kwargs}")
            try: self._openai_client_cache[client_cache_key] = AsyncOpenAI(**filtered_kwargs)
            except Exception as e: raise ValueError(f"Failed to init OpenAI client: {e}") from e
        client = self._openai_client_cache[client_cache_key]
        logger.debug(f"Instantiating OpenAIChatCompletionsModel(model='{model_name}') for '{profile_name}'.")
        try:
            model_instance = OpenAIChatCompletionsModel(model=model_name, openai_client=client)
            self._model_instance_cache[profile_name] = model_instance
            return model_instance
        except Exception as e: raise ValueError(f"Failed to init LLM provider: {e}") from e

    def create_starting_agent(self, mcp_servers: list['MCPServer']) -> 'Agent':
        logger.debug("Creating Zeus agent team...")
        self._model_instance_cache = {}
        self._openai_client_cache = {}
        default_profile_name = self.config.get("llm_profile", "default")
        logger.debug(f"Using LLM profile '{default_profile_name}' for Zeus agents.")
        model_instance = self._get_model_instance(default_profile_name)
        def get_agent_mcps(names: list[str]) -> list['MCPServer']:
            return [s for s in mcp_servers if s.name in names]
        odin_agent = Agent(name="Odin", model=model_instance, instructions=odin_instructions, tools=[], mcp_servers=get_agent_mcps(["brave-search"]))
        hermes_agent = Agent(name="Hermes", model=model_instance, instructions=hermes_instructions, tools=[], mcp_servers=get_agent_mcps(["mcp-shell"]))
        hephaestus_agent = Agent(name="Hephaestus", model=model_instance, instructions=hephaestus_instructions, tools=[], mcp_servers=get_agent_mcps(["filesystem"]))
        hecate_agent = Agent(name="Hecate", model=model_instance, instructions=hecate_instructions, tools=[], mcp_servers=get_agent_mcps(["filesystem"]))
        thoth_agent = Agent(name="Thoth", model=model_instance, instructions=thoth_instructions, tools=[], mcp_servers=get_agent_mcps(["sqlite", "filesystem"]))
        mnemosyne_agent = Agent(name="Mnemosyne", model=model_instance, instructions=mnemosyne_instructions, tools=[], mcp_servers=get_agent_mcps(["mcp-shell", "memory"]))
        chronos_agent = Agent(name="Chronos", model=model_instance, instructions=chronos_instructions, tools=[], mcp_servers=get_agent_mcps(["sequential-thinking", "filesystem"]))
        odin_agent.tools.extend([read_file_tool, write_file_tool, list_files_tool, execute_shell_command_tool])
        hermes_agent.tools.extend([read_file_tool, write_file_tool, list_files_tool, execute_shell_command_tool])
        hephaestus_agent.tools.extend([read_file_tool, write_file_tool, list_files_tool, execute_shell_command_tool])
        hecate_agent.tools.extend([read_file_tool, write_file_tool, list_files_tool, execute_shell_command_tool])
        thoth_agent.tools.extend([read_file_tool, write_file_tool, list_files_tool, execute_shell_command_tool])
        mnemosyne_agent.tools.extend([read_file_tool, write_file_tool, list_files_tool, execute_shell_command_tool])
        chronos_agent.tools.extend([read_file_tool, write_file_tool, list_files_tool, execute_shell_command_tool])
        zeus_agent = Agent(
            name="Zeus",
            model=model_instance,
            instructions=zeus_instructions,
            tools=[
                odin_agent.as_tool(tool_name="Odin", tool_description="Delegate architecture design or research tasks."),
                hermes_agent.as_tool(tool_name="Hermes", tool_description="Delegate task breakdown or system setup/checks."),
                hephaestus_agent.as_tool(tool_name="Hephaestus", tool_description="Delegate core coding implementation tasks."),
                hecate_agent.as_tool(tool_name="Hecate", tool_description="Delegate specific, smaller coding tasks (usually requested by Hephaestus)."),
                thoth_agent.as_tool(tool_name="Thoth", tool_description="Delegate database updates or code management tasks."),
                mnemosyne_agent.as_tool(tool_name="Mnemosyne", tool_description="Delegate DevOps, deployment, or workflow optimization tasks."),
                chronos_agent.as_tool(tool_name="Chronos", tool_description="Delegate documentation writing tasks.")
            ],
            mcp_servers=mcp_servers
        )
        logger.debug("Zeus Team (Zeus & Pantheon) created successfully. Zeus is starting agent.")
        return zeus_agent

    async def _run_non_interactive(self, instruction: str, **kwargs) -> Any:
        logger.info(f"Running Zeus non-interactively with instruction: '{instruction[:100]}...'")
        mcp_servers = kwargs.get("mcp_servers", [])
        agent = self.create_starting_agent(mcp_servers=mcp_servers)
        import time

        from agents import Runner
        op_start = time.monotonic()
        try:
            response = await Runner.run(agent, instruction)
            llm_response = getattr(response, 'final_output', str(response))
            results = [llm_response.strip() or "(No response from LLM)"]
            spinner_state = get_spinner_state(op_start)
            print_operation_box(
                op_type="Zeus Result",
                results=["Zeus Result", "Found", results[0], "Processed"],
                params=None,
                result_type="zeus",
                summary="Zeus agent response",
                progress_line=None,
                spinner_state=spinner_state,
                operation_type="Zeus Run",
                search_mode=None,
                total_lines=None
            )
            yield {"messages": [{"role": "assistant", "content": results[0]}]}
        except Exception as e:
            logger.error(f"Error during non-interactive run: {e}", exc_info=True)
            spinner_state = get_spinner_state(op_start)
            print_operation_box(
                op_type="Zeus Error",
                results=["Zeus Error", "Found", f"An error occurred: {e}", "Agent-based LLM not available.", "Processed"],
                params=None,
                result_type="zeus",
                summary="Zeus agent error",
                progress_line=None,
                spinner_state=spinner_state,
                operation_type="Zeus Run",
                search_mode=None,
                total_lines=None
            )
            yield {"messages": [{"role": "assistant", "content": f"An error occurred: {e}\nAgent-based LLM not available."}]}

    async def run(self, messages: list[dict[str, Any]], **kwargs) -> Any:
        logger.info("ZeusBlueprint run method called.")
        import time
        op_start = time.monotonic()
        from swarm.core.output_utils import get_spinner_state, print_operation_box
        instruction = messages[-1].get("content", "") if messages else ""
        if not instruction:
            spinner_state = get_spinner_state(op_start)
            print_operation_box(
                op_type="Zeus Error",
                results=["Zeus Error", "Found", "I need a user message to proceed.", "Processed"],
                params=None,
                result_type="zeus",
                summary="No user message provided",
                progress_line=None,
                spinner_state=spinner_state,
                operation_type="Zeus Run",
                search_mode=None,
                total_lines=None
            )
            yield {"messages": [{"role": "assistant", "content": "I need a user message to proceed."}]}
            return
        spinner_state = get_spinner_state(op_start)
        print_operation_box(
            op_type="Zeus Input",
            results=["Zeus Input", "Found", instruction, "Processed"],
            params=None,
            result_type="zeus",
            summary="User instruction received",
            progress_line=None,
            spinner_state=spinner_state,
            operation_type="Zeus Run",
            search_mode=None,
            total_lines=None
        )

        if os.environ.get('SWARM_TEST_MODE'):
            from swarm.core.output_utils import print_search_progress_box, get_spinner_state
            spinner_lines = [
                "Generating.",
                "Generating..",
                "Generating...",
                "Running..."
            ]
            ZeusBlueprint.print_search_progress_box(
                op_type="Zeus Spinner",
                results=[
                    "Zeus Search",
                    f"Searching for: '{instruction}'",
                    *spinner_lines,
                    "Results: 2",
                    "Processed",
                    "⚡"
                ],
                params=None,
                result_type="zeus",
                summary=f"Searching for: '{instruction}'",
                progress_line=None,
                spinner_state="Generating... Taking longer than expected",
                operation_type="Zeus Spinner",
                search_mode=None,
                total_lines=None,
                emoji='⚡',
                border='╔'
            )
            for i, spinner_state in enumerate(spinner_lines + ["Generating... Taking longer than expected"], 1):
                progress_line = f"Spinner {i}/{len(spinner_lines) + 1}"
                ZeusBlueprint.print_search_progress_box(
                    op_type="Zeus Spinner",
                    results=[f"Spinner State: {spinner_state}"],
                    params=None,
                    result_type="zeus",
                    summary=f"Spinner progress for: '{instruction}'",
                    progress_line=progress_line,
                    spinner_state=spinner_state,
                    operation_type="Zeus Spinner",
                    search_mode=None,
                    total_lines=None,
                    emoji='⚡',
                    border='╔'
                )
                import asyncio; await asyncio.sleep(0.01)
            ZeusBlueprint.print_search_progress_box(
                op_type="Zeus Results",
                results=[f"Zeus agent response for: '{instruction}'", "Found 2 results.", "Processed"],
                params=None,
                result_type="zeus",
                summary=f"Zeus agent response for: '{instruction}'",
                progress_line="Processed",
                spinner_state="Done",
                operation_type="Zeus Results",
                search_mode=None,
                total_lines=None,
                emoji='⚡',
                border='╔'
            )
            return
        # After LLM/agent run, show a creative output box with the main result
        async for chunk in self._run_non_interactive(instruction, **kwargs):
            yield chunk
        logger.info("ZeusBlueprint run method finished.")

    @staticmethod
    def print_search_progress_box(*args, **kwargs):
        from swarm.core.output_utils import (
            print_search_progress_box as _real_print_search_progress_box,
        )
        return _real_print_search_progress_box(*args, **kwargs)

    async def demo_code_search(self, query: str, directory: str = "."):
        import os
        import time
        from glob import glob

        from swarm.core.output_utils import get_spinner_state
        op_start = time.monotonic()
        matches = []
        py_files = [y for x in os.walk(directory) for y in glob(os.path.join(x[0], '*.py'))]
        total_files = len(py_files)
        params = {"query": query, "directory": directory, "filetypes": ".py"}
        ZeusBlueprint.print_search_progress_box(
            op_type="Code Search",
            results=["Code Search", f"Searching for '{query}' in {total_files} Python files..."],
            params=params,
            result_type="code",
            summary=f"Searched filesystem for: '{query}'",
            progress_line=None,
            spinner_state=get_spinner_state(op_start),
            operation_type="Zeus Code Search",
            search_mode="keyword",
            total_lines=total_files,
            emoji='⚡',
            border='╔'
        )
        for idx, file in enumerate(py_files, 1):
            try:
                with open(file, encoding='utf-8', errors='ignore') as f:
                    for lineno, line in enumerate(f, 1):
                        if query in line:
                            matches.append(f"{file}:{lineno}: {line.strip()}")
            except Exception as e:
                matches.append(f"ERROR in {file}: {e}")
            if idx % 10 == 0 or idx == total_files:
                spinner_state = get_spinner_state(op_start)
                ZeusBlueprint.print_search_progress_box(
                    op_type="Code Search Progress",
                    results=["Code Search", f"Found {len(matches)} matches so far."],
                    params=params,
                    result_type="code",
                    summary=f"Searching for '{query}'...",
                    progress_line=f"Processed {idx}/{total_files} files...",
                    spinner_state=spinner_state,
                    operation_type="Zeus Code Search",
                    search_mode="keyword",
                    total_lines=total_files,
                    emoji='⚡',
                    border='╔'
                )
        spinner_state = get_spinner_state(op_start)
        ZeusBlueprint.print_search_progress_box(
            op_type="Code Search",
            results=["Code Search"] + (matches if matches else ["No matches found."]) + ["Processed"],
            params=params,
            result_type="code",
            summary=f"Searched filesystem for: '{query}'",
            progress_line="Processed",
            spinner_state=spinner_state,
            operation_type="Zeus Code Search",
            search_mode="keyword",
            total_lines=total_files,
            emoji='⚡',
            border='╔'
        )
        return matches

    async def demo_semantic_search(self, query: str, directory: str = "."):
        import os
        import time
        from glob import glob

        from swarm.core.output_utils import get_spinner_state
        op_start = time.monotonic()
        py_files = [y for x in os.walk(directory) for y in glob(os.path.join(x[0], '*.py'))]
        total_files = len(py_files)
        params = {"query": query, "directory": directory, "filetypes": ".py", "semantic": True}
        matches = []
        ZeusBlueprint.print_search_progress_box(
            op_type="Zeus Semantic Search",
            results=["Zeus Semantic Search", "Found", f"Semantic code search for '{query}' in {total_files} Python files...", "Processed"],
            params=params,
            result_type="semantic",
            summary=f"Semantic Search for: '{query}'",
            progress_line=None,
            spinner_state=get_spinner_state(op_start),
            operation_type="Zeus Semantic Search",
            search_mode="semantic",
            total_lines=total_files,
            emoji='⚡',
            border='╔'
        )
        import random
        for idx, file in enumerate(py_files, 1):
            if random.random() < 0.0005:
                matches.append(f"[Semantic] {file}: relevant to '{query}'")
            if idx % 10 == 0 or idx == total_files:
                spinner_state = get_spinner_state(op_start)
                ZeusBlueprint.print_search_progress_box(
                    op_type="Semantic Search Progress",
                    results=["Zeus Semantic Search", "Found", f"Found {len(matches)} semantic matches so far.", "Processed"],
                    params=params,
                    result_type="semantic",
                    summary=f"Analyzing for '{query}'...",
                    progress_line=f"Processed {idx}/{total_files} files...",
                    spinner_state=spinner_state,
                    operation_type="Zeus Semantic Search",
                    search_mode="semantic",
                    total_lines=total_files,
                    emoji='⚡',
                    border='╔'
                )
        spinner_state = get_spinner_state(op_start)
        ZeusBlueprint.print_search_progress_box(
            op_type="Zeus Semantic Search",
            results=["Zeus Semantic Search", "Found"] + (matches if matches else ["No semantic matches found."]) + ["Processed"],
            params=params,
            result_type="semantic",
            summary=f"Semantic Search for: '{query}'",
            progress_line="Processed",
            spinner_state=spinner_state,
            operation_type="Zeus Semantic Search",
            search_mode="semantic",
            total_lines=total_files,
            emoji='⚡',
            border='╔'
        )
        return matches
